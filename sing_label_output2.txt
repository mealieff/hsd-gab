== Directory: sing_label_data ==

== Training with: sing_label_data/multiclass_ADASYN_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.830
Recall:    0.824
F1 Score:  0.826

Microaveraged Scores per Label:
HD: Precision=0.311 Recall=0.214 F1=0.253
CV: Precision=0.077 Recall=0.167 F1=0.105
VO: Precision=0.298 Recall=0.214 F1=0.249
NONE: Precision=0.903 Recall=0.913 F1=0.908
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_ADASYN_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.844
Recall:    0.839
F1 Score:  0.841

Microaveraged Scores per Label:
HD: Precision=0.333 Recall=0.159 F1=0.215
CV: Precision=0.091 Recall=0.167 F1=0.118
VO: Precision=0.307 Recall=0.165 F1=0.215
NONE: Precision=0.895 Recall=0.938 F1=0.916
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_ADASYN_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.855
Recall:    0.852
F1 Score:  0.853

Microaveraged Scores per Label:
HD: Precision=0.348 Recall=0.110 F1=0.167
CV: Precision=0.108 Recall=0.167 F1=0.131
VO: Precision=0.341 Recall=0.119 F1=0.177
NONE: Precision=0.888 Recall=0.960 F1=0.923
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_ADASYN_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.866
Recall:    0.864
F1 Score:  0.865

Microaveraged Scores per Label:
HD: Precision=0.418 Recall=0.057 F1=0.100
CV: Precision=0.120 Recall=0.125 F1=0.122
VO: Precision=0.377 Recall=0.054 F1=0.095
NONE: Precision=0.880 Recall=0.983 F1=0.928
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_ADASYN_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.859
Recall:    0.858
F1 Score:  0.858

Microaveraged Scores per Label:
HD: Precision=0.286 Recall=0.045 F1=0.077
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.250 Recall=0.057 F1=0.093
NONE: Precision=0.877 Recall=0.977 F1=0.924
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.865
Recall:    0.863
F1 Score:  0.864

Microaveraged Scores per Label:
HD: Precision=0.220 Recall=0.018 F1=0.034
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.309 Recall=0.046 F1=0.080
NONE: Precision=0.875 Recall=0.986 F1=0.927
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.868
Recall:    0.868
F1 Score:  0.868

Microaveraged Scores per Label:
HD: Precision=0.158 Recall=0.006 F1=0.012
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.360 Recall=0.024 F1=0.046
NONE: Precision=0.873 Recall=0.994 F1=0.930
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.871
Recall:    0.871
F1 Score:  0.871

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.600 Recall=0.008 F1=0.016
NONE: Precision=0.872 Recall=0.999 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.836
Recall:    0.832
F1 Score:  0.833

Microaveraged Scores per Label:
HD: Precision=0.323 Recall=0.175 F1=0.227
CV: Precision=0.058 Recall=0.125 F1=0.079
VO: Precision=0.279 Recall=0.154 F1=0.199
NONE: Precision=0.895 Recall=0.929 F1=0.912
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.849
Recall:    0.845
F1 Score:  0.846

Microaveraged Scores per Label:
HD: Precision=0.345 Recall=0.124 F1=0.183
CV: Precision=0.071 Recall=0.125 F1=0.091
VO: Precision=0.301 Recall=0.117 F1=0.168
NONE: Precision=0.888 Recall=0.951 F1=0.918
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.859
Recall:    0.857
F1 Score:  0.858

Microaveraged Scores per Label:
HD: Precision=0.374 Recall=0.069 F1=0.117
CV: Precision=0.081 Recall=0.125 F1=0.098
VO: Precision=0.318 Recall=0.073 F1=0.119
NONE: Precision=0.881 Recall=0.972 F1=0.925
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.866
Recall:    0.866
F1 Score:  0.866

Microaveraged Scores per Label:
HD: Precision=0.429 Recall=0.037 F1=0.068
CV: Precision=0.115 Recall=0.125 F1=0.120
VO: Precision=0.333 Recall=0.035 F1=0.064
NONE: Precision=0.877 Recall=0.986 F1=0.928
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomOverSampler_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.821
Recall:    0.819
F1 Score:  0.819

Microaveraged Scores per Label:
HD: Precision=0.215 Recall=0.126 F1=0.159
CV: Precision=0.061 Recall=0.083 F1=0.070
VO: Precision=0.123 Recall=0.046 F1=0.067
NONE: Precision=0.879 Recall=0.925 F1=0.901
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.841
Recall:    0.840
F1 Score:  0.841

Microaveraged Scores per Label:
HD: Precision=0.229 Recall=0.088 F1=0.127
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.114 Recall=0.022 F1=0.036
NONE: Precision=0.876 Recall=0.955 F1=0.914
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.858
Recall:    0.857
F1 Score:  0.858

Microaveraged Scores per Label:
HD: Precision=0.208 Recall=0.041 F1=0.068
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.179 Recall=0.014 F1=0.025
NONE: Precision=0.874 Recall=0.979 F1=0.924
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.868
Recall:    0.868
F1 Score:  0.868

Microaveraged Scores per Label:
HD: Precision=0.276 Recall=0.016 F1=0.031
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=0.994 F1=0.929
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_RandomUnderSampler_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTEENN_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.663
Recall:    0.654
F1 Score:  0.657

Microaveraged Scores per Label:
HD: Precision=0.173 Recall=0.344 F1=0.231
CV: Precision=0.032 Recall=0.125 F1=0.050
VO: Precision=0.157 Recall=0.320 F1=0.210
NONE: Precision=0.912 Recall=0.700 F1=0.792
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTEENN_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.701
Recall:    0.693
F1 Score:  0.696

Microaveraged Scores per Label:
HD: Precision=0.178 Recall=0.293 F1=0.222
CV: Precision=0.034 Recall=0.125 F1=0.054
VO: Precision=0.167 Recall=0.282 F1=0.210
NONE: Precision=0.904 Recall=0.751 F1=0.821
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTEENN_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.743
Recall:    0.738
F1 Score:  0.739

Microaveraged Scores per Label:
HD: Precision=0.184 Recall=0.230 F1=0.205
CV: Precision=0.039 Recall=0.125 F1=0.059
VO: Precision=0.171 Recall=0.214 F1=0.190
NONE: Precision=0.895 Recall=0.811 F1=0.851
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTEENN_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.790
Recall:    0.787
F1 Score:  0.788

Microaveraged Scores per Label:
HD: Precision=0.204 Recall=0.169 F1=0.185
CV: Precision=0.049 Recall=0.125 F1=0.071
VO: Precision=0.175 Recall=0.138 F1=0.155
NONE: Precision=0.887 Recall=0.878 F1=0.883
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTEENN_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTE_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.833
Recall:    0.828
F1 Score:  0.829

Microaveraged Scores per Label:
HD: Precision=0.319 Recall=0.216 F1=0.258
CV: Precision=0.075 Recall=0.167 F1=0.104
VO: Precision=0.320 Recall=0.225 F1=0.264
NONE: Precision=0.903 Recall=0.915 F1=0.909
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTE_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.846
Recall:    0.842
F1 Score:  0.843

Microaveraged Scores per Label:
HD: Precision=0.345 Recall=0.163 F1=0.221
CV: Precision=0.098 Recall=0.167 F1=0.123
VO: Precision=0.321 Recall=0.163 F1=0.216
NONE: Precision=0.894 Recall=0.940 F1=0.917
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTE_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.855
Recall:    0.853
F1 Score:  0.853

Microaveraged Scores per Label:
HD: Precision=0.351 Recall=0.108 F1=0.165
CV: Precision=0.086 Recall=0.125 F1=0.102
VO: Precision=0.336 Recall=0.108 F1=0.164
NONE: Precision=0.887 Recall=0.961 F1=0.923
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTE_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.866
Recall:    0.865
F1 Score:  0.866

Microaveraged Scores per Label:
HD: Precision=0.444 Recall=0.057 F1=0.101
CV: Precision=0.111 Recall=0.125 F1=0.118
VO: Precision=0.415 Recall=0.060 F1=0.104
NONE: Precision=0.880 Recall=0.983 F1=0.928
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_SMOTE_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_TomekLinks_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.873
Recall:    0.873
F1 Score:  0.873

Microaveraged Scores per Label:
HD: Precision=0.571 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.722 Recall=0.035 F1=0.067
NONE: Precision=0.874 Recall=0.998 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_TomekLinks_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.873
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.600 Recall=0.006 F1=0.012
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.692 Recall=0.024 F1=0.047
NONE: Precision=0.873 Recall=0.999 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_TomekLinks_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.500 Recall=0.002 F1=0.004
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.625 Recall=0.014 F1=0.027
NONE: Precision=0.873 Recall=0.999 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_TomekLinks_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data/multiclass_TomekLinks_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.
== Directory: sing_label_data2_1 ==

== Training with: sing_label_data2_1/multiclass_ADASYN_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.830
Recall:    0.824
F1 Score:  0.826

Microaveraged Scores per Label:
HD: Precision=0.311 Recall=0.214 F1=0.253
CV: Precision=0.077 Recall=0.167 F1=0.105
VO: Precision=0.298 Recall=0.214 F1=0.249
NONE: Precision=0.903 Recall=0.913 F1=0.908
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_ADASYN_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.844
Recall:    0.839
F1 Score:  0.841

Microaveraged Scores per Label:
HD: Precision=0.333 Recall=0.159 F1=0.215
CV: Precision=0.091 Recall=0.167 F1=0.118
VO: Precision=0.307 Recall=0.165 F1=0.215
NONE: Precision=0.895 Recall=0.938 F1=0.916
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_ADASYN_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.855
Recall:    0.852
F1 Score:  0.853

Microaveraged Scores per Label:
HD: Precision=0.348 Recall=0.110 F1=0.167
CV: Precision=0.108 Recall=0.167 F1=0.131
VO: Precision=0.341 Recall=0.119 F1=0.177
NONE: Precision=0.888 Recall=0.960 F1=0.923
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_ADASYN_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.866
Recall:    0.864
F1 Score:  0.865

Microaveraged Scores per Label:
HD: Precision=0.418 Recall=0.057 F1=0.100
CV: Precision=0.120 Recall=0.125 F1=0.122
VO: Precision=0.377 Recall=0.054 F1=0.095
NONE: Precision=0.880 Recall=0.983 F1=0.928
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_ADASYN_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.859
Recall:    0.858
F1 Score:  0.858

Microaveraged Scores per Label:
HD: Precision=0.286 Recall=0.045 F1=0.077
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.250 Recall=0.057 F1=0.093
NONE: Precision=0.877 Recall=0.977 F1=0.924
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.865
Recall:    0.863
F1 Score:  0.864

Microaveraged Scores per Label:
HD: Precision=0.220 Recall=0.018 F1=0.034
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.309 Recall=0.046 F1=0.080
NONE: Precision=0.875 Recall=0.986 F1=0.927
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.868
Recall:    0.868
F1 Score:  0.868

Microaveraged Scores per Label:
HD: Precision=0.158 Recall=0.006 F1=0.012
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.360 Recall=0.024 F1=0.046
NONE: Precision=0.873 Recall=0.994 F1=0.930
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.871
Recall:    0.871
F1 Score:  0.871

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.600 Recall=0.008 F1=0.016
NONE: Precision=0.872 Recall=0.999 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_CondensedNearestNeighbour_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.836
Recall:    0.832
F1 Score:  0.833

Microaveraged Scores per Label:
HD: Precision=0.323 Recall=0.175 F1=0.227
CV: Precision=0.058 Recall=0.125 F1=0.079
VO: Precision=0.279 Recall=0.154 F1=0.199
NONE: Precision=0.895 Recall=0.929 F1=0.912
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.849
Recall:    0.845
F1 Score:  0.846

Microaveraged Scores per Label:
HD: Precision=0.345 Recall=0.124 F1=0.183
CV: Precision=0.071 Recall=0.125 F1=0.091
VO: Precision=0.301 Recall=0.117 F1=0.168
NONE: Precision=0.888 Recall=0.951 F1=0.918
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.859
Recall:    0.857
F1 Score:  0.858

Microaveraged Scores per Label:
HD: Precision=0.374 Recall=0.069 F1=0.117
CV: Precision=0.081 Recall=0.125 F1=0.098
VO: Precision=0.318 Recall=0.073 F1=0.119
NONE: Precision=0.881 Recall=0.972 F1=0.925
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.866
Recall:    0.866
F1 Score:  0.866

Microaveraged Scores per Label:
HD: Precision=0.429 Recall=0.037 F1=0.068
CV: Precision=0.115 Recall=0.125 F1=0.120
VO: Precision=0.333 Recall=0.035 F1=0.064
NONE: Precision=0.877 Recall=0.986 F1=0.928
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.821
Recall:    0.819
F1 Score:  0.819

Microaveraged Scores per Label:
HD: Precision=0.215 Recall=0.126 F1=0.159
CV: Precision=0.061 Recall=0.083 F1=0.070
VO: Precision=0.123 Recall=0.046 F1=0.067
NONE: Precision=0.879 Recall=0.925 F1=0.901
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.841
Recall:    0.840
F1 Score:  0.841

Microaveraged Scores per Label:
HD: Precision=0.229 Recall=0.088 F1=0.127
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.114 Recall=0.022 F1=0.036
NONE: Precision=0.876 Recall=0.955 F1=0.914
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.858
Recall:    0.857
F1 Score:  0.858

Microaveraged Scores per Label:
HD: Precision=0.208 Recall=0.041 F1=0.068
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.179 Recall=0.014 F1=0.025
NONE: Precision=0.874 Recall=0.979 F1=0.924
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.868
Recall:    0.868
F1 Score:  0.868

Microaveraged Scores per Label:
HD: Precision=0.276 Recall=0.016 F1=0.031
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=0.994 F1=0.929
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTEENN_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.663
Recall:    0.654
F1 Score:  0.657

Microaveraged Scores per Label:
HD: Precision=0.173 Recall=0.344 F1=0.231
CV: Precision=0.032 Recall=0.125 F1=0.050
VO: Precision=0.157 Recall=0.320 F1=0.210
NONE: Precision=0.912 Recall=0.700 F1=0.792
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTEENN_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.701
Recall:    0.693
F1 Score:  0.696

Microaveraged Scores per Label:
HD: Precision=0.178 Recall=0.293 F1=0.222
CV: Precision=0.034 Recall=0.125 F1=0.054
VO: Precision=0.167 Recall=0.282 F1=0.210
NONE: Precision=0.904 Recall=0.751 F1=0.821
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTEENN_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.743
Recall:    0.738
F1 Score:  0.739

Microaveraged Scores per Label:
HD: Precision=0.184 Recall=0.230 F1=0.205
CV: Precision=0.039 Recall=0.125 F1=0.059
VO: Precision=0.171 Recall=0.214 F1=0.190
NONE: Precision=0.895 Recall=0.811 F1=0.851
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTEENN_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.790
Recall:    0.787
F1 Score:  0.788

Microaveraged Scores per Label:
HD: Precision=0.204 Recall=0.169 F1=0.185
CV: Precision=0.049 Recall=0.125 F1=0.071
VO: Precision=0.175 Recall=0.138 F1=0.155
NONE: Precision=0.887 Recall=0.878 F1=0.883
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTEENN_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTE_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.833
Recall:    0.828
F1 Score:  0.829

Microaveraged Scores per Label:
HD: Precision=0.319 Recall=0.216 F1=0.258
CV: Precision=0.075 Recall=0.167 F1=0.104
VO: Precision=0.320 Recall=0.225 F1=0.264
NONE: Precision=0.903 Recall=0.915 F1=0.909
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTE_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.846
Recall:    0.842
F1 Score:  0.843

Microaveraged Scores per Label:
HD: Precision=0.345 Recall=0.163 F1=0.221
CV: Precision=0.098 Recall=0.167 F1=0.123
VO: Precision=0.321 Recall=0.163 F1=0.216
NONE: Precision=0.894 Recall=0.940 F1=0.917
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTE_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.855
Recall:    0.853
F1 Score:  0.853

Microaveraged Scores per Label:
HD: Precision=0.351 Recall=0.108 F1=0.165
CV: Precision=0.086 Recall=0.125 F1=0.102
VO: Precision=0.336 Recall=0.108 F1=0.164
NONE: Precision=0.887 Recall=0.961 F1=0.923
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTE_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.866
Recall:    0.865
F1 Score:  0.866

Microaveraged Scores per Label:
HD: Precision=0.444 Recall=0.057 F1=0.101
CV: Precision=0.111 Recall=0.125 F1=0.118
VO: Precision=0.415 Recall=0.060 F1=0.104
NONE: Precision=0.880 Recall=0.983 F1=0.928
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_SMOTE_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_TomekLinks_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.873
Recall:    0.873
F1 Score:  0.873

Microaveraged Scores per Label:
HD: Precision=0.571 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.722 Recall=0.035 F1=0.067
NONE: Precision=0.874 Recall=0.998 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_TomekLinks_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.873
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.600 Recall=0.006 F1=0.012
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.692 Recall=0.024 F1=0.047
NONE: Precision=0.873 Recall=0.999 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_TomekLinks_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.500 Recall=0.002 F1=0.004
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.625 Recall=0.014 F1=0.027
NONE: Precision=0.873 Recall=0.999 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_TomekLinks_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data2_1/multiclass_TomekLinks_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.
== Directory: sing_label_data3_1 ==

== Training with: sing_label_data3_1/multiclass_ADASYN_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.873
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.667 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.625 Recall=0.027 F1=0.052
NONE: Precision=0.874 Recall=0.998 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_ADASYN_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.873
Recall:    0.873
F1 Score:  0.873

Microaveraged Scores per Label:
HD: Precision=0.800 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.727 Recall=0.022 F1=0.042
NONE: Precision=0.873 Recall=0.999 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_ADASYN_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.500 Recall=0.002 F1=0.004
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.750 Recall=0.008 F1=0.016
NONE: Precision=0.872 Recall=1.000 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_ADASYN_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_ADASYN_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.873
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.667 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.625 Recall=0.027 F1=0.052
NONE: Precision=0.874 Recall=0.998 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.873
Recall:    0.873
F1 Score:  0.873

Microaveraged Scores per Label:
HD: Precision=0.800 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.727 Recall=0.022 F1=0.042
NONE: Precision=0.873 Recall=0.999 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.500 Recall=0.002 F1=0.004
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.750 Recall=0.008 F1=0.016
NONE: Precision=0.872 Recall=1.000 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomOverSampler_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.873
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.667 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.625 Recall=0.027 F1=0.052
NONE: Precision=0.874 Recall=0.998 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.873
Recall:    0.873
F1 Score:  0.873

Microaveraged Scores per Label:
HD: Precision=0.800 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.727 Recall=0.022 F1=0.042
NONE: Precision=0.873 Recall=0.999 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.500 Recall=0.002 F1=0.004
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.750 Recall=0.008 F1=0.016
NONE: Precision=0.872 Recall=1.000 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_RandomUnderSampler_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTEENN_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.663
Recall:    0.654
F1 Score:  0.657

Microaveraged Scores per Label:
HD: Precision=0.173 Recall=0.344 F1=0.231
CV: Precision=0.032 Recall=0.125 F1=0.050
VO: Precision=0.157 Recall=0.320 F1=0.210
NONE: Precision=0.912 Recall=0.700 F1=0.792
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTEENN_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.701
Recall:    0.693
F1 Score:  0.696

Microaveraged Scores per Label:
HD: Precision=0.178 Recall=0.293 F1=0.222
CV: Precision=0.034 Recall=0.125 F1=0.054
VO: Precision=0.167 Recall=0.282 F1=0.210
NONE: Precision=0.904 Recall=0.751 F1=0.821
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTEENN_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.743
Recall:    0.738
F1 Score:  0.739

Microaveraged Scores per Label:
HD: Precision=0.184 Recall=0.230 F1=0.205
CV: Precision=0.039 Recall=0.125 F1=0.059
VO: Precision=0.171 Recall=0.214 F1=0.190
NONE: Precision=0.895 Recall=0.811 F1=0.851
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTEENN_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.790
Recall:    0.787
F1 Score:  0.788

Microaveraged Scores per Label:
HD: Precision=0.204 Recall=0.169 F1=0.185
CV: Precision=0.049 Recall=0.125 F1=0.071
VO: Precision=0.175 Recall=0.138 F1=0.155
NONE: Precision=0.887 Recall=0.878 F1=0.883
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTEENN_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTE_single_label.npy | Threshold: 0.8 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.8

Partial Evaluation Results:
Precision: 0.873
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.667 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.625 Recall=0.027 F1=0.052
NONE: Precision=0.874 Recall=0.998 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTE_single_label.npy | Threshold: 0.85 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.85

Partial Evaluation Results:
Precision: 0.873
Recall:    0.873
F1 Score:  0.873

Microaveraged Scores per Label:
HD: Precision=0.800 Recall=0.008 F1=0.016
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.727 Recall=0.022 F1=0.042
NONE: Precision=0.873 Recall=0.999 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTE_single_label.npy | Threshold: 0.9 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.9

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.500 Recall=0.002 F1=0.004
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.750 Recall=0.008 F1=0.016
NONE: Precision=0.872 Recall=1.000 F1=0.932
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTE_single_label.npy | Threshold: 0.95 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 0.95

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.

== Training with: sing_label_data3_1/multiclass_SMOTE_single_label.npy | Threshold: 1.0 ==
Loading training data...
Loading test data...
Training model...
Evaluating with threshold: 1.0

Partial Evaluation Results:
Precision: 0.872
Recall:    0.872
F1 Score:  0.872

Microaveraged Scores per Label:
HD: Precision=0.000 Recall=0.000 F1=0.000
CV: Precision=0.000 Recall=0.000 F1=0.000
VO: Precision=0.000 Recall=0.000 F1=0.000
NONE: Precision=0.872 Recall=1.000 F1=0.931
Saved full confidence outputs to 'test_output_confidences.npy'.
